{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hPbP053j7wy"
   },
   "source": [
    "# Natural Language Inference\n",
    "\n",
    "This Jupyter Notebook fine-tunes `microsoft/mdeberta-v3-base` on the `Contradictory, My Dear Watson` dataset.\n",
    "It includes data loading, preprocessing, data augmentation, model training, evaluation, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb4jC0vEj7w0"
   },
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqhGjxHoj7w0"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -qU pandas numpy \"torch<2.6\" seaborn matplotlib scikit-learn transformers[torch] datasets nltk nlpaug\n",
    "# %pip install -qU protobuf tiktoken sentencepiece # depends on models used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbTlBIhLj7w1"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tw4RAm1zj7w1"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "# Data augmentation\n",
    "from nlpaug.augmenter.word import WordAugmenter, RandomWordAug, SynonymAug\n",
    "from nlpaug.augmenter.char import KeyboardAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8Bk9-ya-7EE"
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = Path.cwd()\n",
    "# Use fixed seed for results reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little trick to prevent nltk downloading outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_silent_download(*args, func=nltk.download, **kwargs):\n",
    "    return func(*args, quiet=True, **kwargs)\n",
    "\n",
    "nltk.download = nltk_silent_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U6tDwWAj7w1"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roW0dM9Mj7w1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_PATH / \"data/train.csv\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4XYZOceWvJ4"
   },
   "source": [
    "Display label distribution: the dataset is evenly distributed across all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iI0wu0VxWt7m"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=df.label.replace({0: \"Entailment\", 1: \"Neutral\", 2: \"Contradiction\"}))\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Pair-wise sentences distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_JGmdbPXSxg"
   },
   "source": [
    "However, the dataset predominantly consists of English sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJcuSwR9VIZm"
   },
   "outputs": [],
   "source": [
    "labels, frequencies = np.unique(df.language.values, return_counts = True)\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.pie(frequencies, labels=labels, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4Nby-Mvj7w2"
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Use `NLPAug` library to augment the data by using synonyms, typo insertion and word swapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WPS4lljj7w2"
   },
   "outputs": [],
   "source": [
    "def augment_text(text, augmenter):\n",
    "    try:\n",
    "        result = augmenter.augment(text)\n",
    "        # Handle list outputs from some augmenters\n",
    "        return result[0] if isinstance(result, list) else str(result)\n",
    "    except Exception as e:\n",
    "        return str(text)  # Ensure string return\n",
    "\n",
    "def augment_df(df, augmenters, sample_frac=0.5):\n",
    "    sample = df.sample(frac=sample_frac)\n",
    "    augmented = []\n",
    "\n",
    "    for _, row in tqdm(sample.iterrows(), total=len(sample)):\n",
    "        for aug, weight in augmenters:\n",
    "            if np.random.random() > weight:\n",
    "                continue  # Skip this augmentation\n",
    "\n",
    "            new_row = row.copy()\n",
    "            premise = new_row['premise'] = augment_text(row['premise'], aug)\n",
    "            hypothesis = new_row['hypothesis'] = augment_text(row['hypothesis'], aug)\n",
    "            if premise != row[\"premise\"] or hypothesis != row[\"hypothesis\"]:\n",
    "                augmented.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(augmented).convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjQLFQq8T7QR"
   },
   "source": [
    "Define augmentation strategies and their probability to be used for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSLivR29BGwt"
   },
   "outputs": [],
   "source": [
    "augmenters = [\n",
    "    (SynonymAug(aug_src='wordnet', aug_p=0.1), 0.8),   # Synonym replacement\n",
    "    (RandomWordAug(action='swap', aug_p=0.1), 0.1),    # Word swapping\n",
    "    (KeyboardAug(aug_char_p=0.1, aug_word_p=0.1), 0.3) # Typo simulation\n",
    "]\n",
    "\n",
    "df_aug = augment_df(df, augmenters)\n",
    "print(f\"Adding {len(df_aug)} new examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBykOxZDj7w3"
   },
   "source": [
    "### Model configuration\n",
    "\n",
    "**Architecture:**  \n",
    "- `microsoft/mdeberta-v3-base` transformer from HuggingFace\n",
    "- Classification head with dropout (0.3)\n",
    "\n",
    "**Training Parameters:**\n",
    "- Batch size: 8 (train), 8 (eval)\n",
    "- Learning rate: 2e-5\n",
    "- Epochs: 5\n",
    "- Weight decay: 0.01\n",
    "- Warmup ratio: 0.1\n",
    "\n",
    "Train using the `Trainer` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyv-9MoVJWy6"
   },
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8o6XGXtgJhGB"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model.classifier.dropout = torch.nn.Dropout(0.3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-ix6gD6JJFR"
   },
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts_F70Doj7w3"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(row):\n",
    "    return tokenizer(\n",
    "        row['premise'],\n",
    "        row['hypothesis'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "# Dataset tokenized\n",
    "dataset = Dataset.from_pandas(df).map(tokenize_function, batched=True)\n",
    "dataset_aug = Dataset.from_pandas(df_aug).map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPKA5r_TJQCf"
   },
   "source": [
    "#### Train-test split:\n",
    "- **Test set** is sampled from original dataset\n",
    "- **Train set** is a concatenation of the sampled train part with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzApPkdTI3o8"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "split_set = dataset.train_test_split(test_size=0.3, seed=0)\n",
    "# Concatenate the augmented set and shuffle the whole set\n",
    "train_set = concatenate_datasets([split_set['train'], dataset_aug]).shuffle()\n",
    "test_set = split_set['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQrSbqSFT7QT"
   },
   "source": [
    "#### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peRqyrEqT7QT"
   },
   "outputs": [],
   "source": [
    "model_path = ROOT_PATH / f\"models/{MODEL_NAME.rpartition('/')[-1]}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    report_to='none'  # Disabling wandb callbacks\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    y_pred = np.argmax(pred.predictions, axis=1)\n",
    "    return {'accuracy': accuracy_score(pred.label_ids, y_pred)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkuxGob7j7w4"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxQF4kis6StP"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aBONMs6Ltem"
   },
   "source": [
    "Save the best model and the tokenizer to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nA9nEKB7LwLl"
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl19KSO2K5PP"
   },
   "source": [
    "### Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ94KVS5LHkg"
   },
   "source": [
    "Compute accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvK1-BMbj7w4"
   },
   "outputs": [],
   "source": [
    "pred = trainer.predict(test_set)\n",
    "y_true = test_set['label']\n",
    "y_pred = np.argmax(pred.predictions, axis=-1)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNVClqebLOXF"
   },
   "source": [
    "Display the confusion matrix using `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d1sOBH1LDcQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred),\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=['Entailment', 'Neutral', 'Contradiction'],\n",
    "            yticklabels=['Entailment', 'Neutral', 'Contradiction'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jF49SrkCLWO7"
   },
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Entailment', 'Neutral', 'Contradiction']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (local)",
   "language": "python",
   "name": ".jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
