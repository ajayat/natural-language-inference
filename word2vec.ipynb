{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first approach : Word2Vec Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle the issue, we first wanted to use basic Word2vec embeddings to represent premises/hypotheses, and then train a simple classifier on these embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import nltk\n",
    "import jieba\n",
    "from arabic_reshaper import reshape\n",
    "from bidi.algorithm import get_display\n",
    "import re\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NLI_dataset.csv') \n",
    "\n",
    "new_df = pd.DataFrame(df)\n",
    "\n",
    "new_df = new_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12120\n",
      "lang_abv\n",
      "en    6870\n",
      "zh     411\n",
      "ar     401\n",
      "fr     390\n",
      "sw     385\n",
      "ur     381\n",
      "vi     379\n",
      "ru     376\n",
      "hi     374\n",
      "el     372\n",
      "th     371\n",
      "es     366\n",
      "tr     351\n",
      "de     351\n",
      "bg     342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(new_df['id'].count())\n",
    "\n",
    "print(new_df['lang_abv'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the data is quite unbalanced, with English sentences being dominant. Tokenizers do not behave well with every language, hence embeddings in less abudant languages could be unrepresentative of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now preprocess the sentences, as usual :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text) \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  \n",
    "    return text\n",
    "\n",
    "\n",
    "new_df['cleaned_premise'] = new_df['premise'].apply(preprocess_text)\n",
    "new_df['cleaned_hypothesis'] = new_df['hypothesis'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a basic tokenizer from `nltk`when available. For unsupported languages, we just split the sentences : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.972 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text, lang):\n",
    "    if lang == \"en\":\n",
    "        return word_tokenize(text, language=\"english\")\n",
    "    elif lang == \"zh\":  \n",
    "        return list(jieba.cut(text))\n",
    "    elif lang == \"ar\":  \n",
    "        reshaped_text = reshape(text)\n",
    "        bidi_text = get_display(reshaped_text)\n",
    "        return word_tokenize(bidi_text, language=\"arabic\")\n",
    "    elif lang == \"fr\":\n",
    "        return word_tokenize(text, language=\"french\")\n",
    "    elif lang == \"de\":\n",
    "        return word_tokenize(text, language=\"german\")\n",
    "    elif lang == \"es\":\n",
    "        return word_tokenize(text, language=\"spanish\")\n",
    "    elif lang == \"tr\":\n",
    "        return word_tokenize(text, language=\"turkish\")\n",
    "    elif lang == \"ru\":\n",
    "        return word_tokenize(text, language=\"russian\")\n",
    "    elif lang in [\"hi\", \"ur\"]:  \n",
    "        return re.findall(r'\\w+', text, re.UNICODE)  \n",
    "    else:\n",
    "        return text.split()  # Basic tokenization for other languages\n",
    "\n",
    "tokenized_by_lang_hyp = {}\n",
    "tokenized_by_lang_pre = {}\n",
    "\n",
    "for lang in new_df['lang_abv'].unique() :\n",
    "    if lang != 'ar' : \n",
    "        hyp_lang = new_df[new_df['lang_abv'] == lang]['cleaned_hypothesis']\n",
    "        tokenized_by_lang_hyp[lang] = [tokenize_text(tweet, lang) for tweet in hyp_lang]\n",
    "        pre_lang = new_df[new_df['lang_abv'] == lang]['cleaned_premise']\n",
    "        tokenized_by_lang_pre[lang] = [tokenize_text(tweet, lang) for tweet in pre_lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokenized_sentences = []\n",
    "\n",
    "for lang in tokenized_by_lang_hyp:\n",
    "    all_tokenized_sentences.extend(tokenized_by_lang_hyp[lang])\n",
    "\n",
    "for lang in tokenized_by_lang_pre:\n",
    "    all_tokenized_sentences.extend(tokenized_by_lang_pre[lang])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Word2vec model to generate token embeddings : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=all_tokenized_sentences, \n",
    "                          window=4,         # Context window size\n",
    "                          min_count=1,      # Ignore words that appear less than this\n",
    "                          sg=1,             # Use skip-gram (1) instead of CBOW (0)\n",
    "                          workers=4)        # Number of threads for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a 4-sized context window to fully grasp a premise/hypothesis' context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Word2vec embeddings do not provide sentence-representative tokens (like `[CLS]` generated by `BERT`'s tokenizer for instance), we compute sentence embeddings by averaging the embeddings of its tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(tweet, model):\n",
    "    tokens = word_tokenize(preprocess_text(tweet))  \n",
    "    embeddings = []\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            embeddings.append(model.wv[word])\n",
    "    \n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)  \n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "X = np.array([get_sentence_embedding(sentence, model) for sentence in new_df['cleaned_premise']]) +np.array([get_sentence_embedding(sentence, model) for sentence in new_df['cleaned_hypothesis']])\n",
    "\n",
    "y = new_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train a vanilla Random Forest classifier to classify these sentence embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "indices = np.arange(len(X))\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    X, y, indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf =  RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's infer !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: Кто? Она спросила его с неожиданным интересом.\n",
      "Hypothesis: Она спросила, как это сделать, так как с её точки зрения это казалось невозможным.\n",
      "Real label: 1\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: Others are Zao (in Tohoku) and a number of resorts in Joshin-etsu Kogen National Park in the Japan Alps, where there are now splendid facilities thanks to the 1998 Winter Olympic Games in Nagano.\n",
      "Hypothesis: There are a lot of resorts in the national park.\n",
      "Real label: 0\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: trying to keep grass alive during a summer on a piece of ground that big was expensive\n",
      "Hypothesis: There was no cost in keeping the grass alive in the summer time.\n",
      "Real label: 2\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: so i guess my experience is is just with what we did and and so they didn't really go through the child care route they were able to be home together\n",
      "Hypothesis: They were able to be home rather than having to worry about getting child care.\n",
      "Real label: 0\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: The Journal put the point succinctly to  Is any publicity good publicity?\n",
      "Hypothesis: The Journal asked \"Is this a good political move?\"\n",
      "Real label: 1\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: Tuy nhiên, email của nhà phân tích phản ánh rằng cô đang bối rối một loạt các rào cản và rào cản pháp lý đối với việc chia sẻ thông tin và các quy tắc điều chỉnh việc sử dụng thông tin của các nhân viên tội phạm thu thập thông qua các kênh tình báo.\n",
      "Hypothesis: Nhà phân tích đã không rõ ràng về nhiều thứ.\n",
      "Real label: 0\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: Ω, παρακαλώ. Υπήρξε πραγματική ανησυχία στη φωνή της.\n",
      "Hypothesis: Η φωνή της έδειξε την ανησυχία της.\n",
      "Real label: 0\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: yeah okay yeah those games are fun to watch you you you watch those games\n",
      "Hypothesis: Those games are a lot of fun.\n",
      "Real label: 0\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: ในฐานะสมาชิกของอินเนอร์เซอร์เคิลคุณจะได้รับสิทธิเลือกที่นั่งในช่วงการประชุม และการรับเชิญอันแสนพิเศษสำหรับรับประทานอาหารเย็น งานเลี้ยง และกิจกรรมกรรมต่างๆตลอดสัปดาห์\n",
      "Hypothesis: สมาชิกวงใน ไม่ได้รับอะไรเลย ในฐานะที่เป็นสมาชิกของกลุ่ม\n",
      "Real label: 2\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: Another White House murder mystery and a chance to bash the genre.\n",
      "Hypothesis: White House murder mystery has other works before this one.\n",
      "Real label: 0\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: Kom Ombo is an unusual temple in that it is dedicated to two gods.\n",
      "Hypothesis: Standard in every way, Kom Ombo is a temple devoted to several deities. \n",
      "Real label: 2\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: 1）增加其他交流方式的渗透\n",
      "Hypothesis: 现在的交流通信占了通信量的60。\n",
      "Real label: 1\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: McKim, kiasi cha hasira yake, sio waliopotea tu bali kuwekwa tatu nyuma ya Howard & amp; Cauldwell.\n",
      "Hypothesis: McKim alifurahi sana kwa kumaliza wa kwanza.\n",
      "Real label: 2\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: In addition, Dublin Tourism has devised and signposted three self-guided walking tours of the city, which you can follow using the booklets provided.\n",
      "Hypothesis: Dublin's self-guided tours are not easy to follow. \n",
      "Real label: 1\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: Khallad е предоставил втора версия, а именно, че и тримата са пътували заедно до Карачи.\n",
      "Hypothesis: Khallad е казал, че тримата са могли да пътуват заедно.\n",
      "Real label: 0\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: We look forward to receiving comments from the readers of this paper.\n",
      "Hypothesis: They discourage people from making comments about the paper.\n",
      "Real label: 2\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: Disney CEO Eisner, who's actually underrated as a pop-culture maven (he was responsible for Happy Days and Welcome Back, Kotter ), insists that ABC's downturn is cyclical and that it will soon return to life.\n",
      "Hypothesis: Eisner is a big fan of ABC.\n",
      "Real label: 1\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: and it's just like college too i think that if a kid goes to college and you can help them fine but i don't think you should pay the whole way\n",
      "Hypothesis: You should pay the whole way for the kid's college tuition.\n",
      "Real label: 2\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: Kill chickens.\n",
      "Hypothesis: Use a knife to kill the chickens.\n",
      "Real label: 1\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: It shows clearly enough that my poor old friend had just found out she'd been made a fool of!\n",
      "Hypothesis: I was relieved that my friend was feeling so well and happy.\n",
      "Real label: 2\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: The data would be presented as required supplementary stewardship information accompanying the consolidated financial statements of the Federal Government but not in individual reports of its component units.\n",
      "Hypothesis: The data would be included in individual reports concerning the constituent units of the federal government.\n",
      "Real label: 2\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: The statue was beheaded several years ago by islanders, who blame Josephine for her role in the slavery in Martinique.\n",
      "Hypothesis: Josephine is responsible for the slavery in Martinique according to locals.\n",
      "Real label: 0\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: An article explains that Al Gore enlisted for the Vietnam War out of fealty to his father and distaste for draft  Gore deplored the inequity of the rich not having to serve.\n",
      "Hypothesis: Gore dodged the draft.\n",
      "Real label: 2\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: although the uh it's uh it we almost one day we painted the house to uh we painted we painted the whole inside and it had all this dark trim we thought uh you know we did the one wall but the other trim i'm trying to think i think i think we left most of it because it gets to be uh they don't do that in the newer houses now we don't the uh mold everything is white in a new house everything is white\n",
      "Hypothesis: We painted the house over the duration of one day.\n",
      "Real label: 0\n",
      "Predicted label: 0\n",
      "\n",
      "Premise: 1 Die Befugnis zur Festlegung von Kraftstoffsparstandards gemäß Abschnitt 32902 wurde vom Sekretär an den Administrator der NHTSA delegiert.\n",
      "Hypothesis: Niemand hat die Befugnis, Kraftstoffnormen vorzuschreiben.\n",
      "Real label: 2\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: Đối với các EGU bị ảnh hưởng cho năm 2010 và mỗi năm sau đó, Quản trị viên sẽ phân bổ các khoản trợ cấp thủy ngân theo mục 474 và tiến hành đấu giá các khoản phụ cấp thủy ngân theo mục 409, theo các số liệu trong Bảng A.\n",
      "Hypothesis: Hạn chế lượng thủy ngân trong hải sản.\n",
      "Real label: 1\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: You wonder what youre going to be when you grow up, lawyer Smith said. \n",
      "Hypothesis: The lawyer, Smith, pointed out that you wanted to know what you would be when you grew up.\n",
      "Real label: 0\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: KSM anaweza kuwa ameagiza Binalishibh atume pesa kwa Moussaoui ili asaidie kutayarisha Moussaoui kama rubani mbadala  mwenye uwezo wa Jarrah.\n",
      "Hypothesis: KSM aliiambia Binalshibh cha kufanya kwa sababu alikuwa mkuu wa shirika zima.\n",
      "Real label: 1\n",
      "Predicted label: 2\n",
      "\n",
      "Premise: His voice was even and calm, not a hint of rage.\n",
      "Hypothesis: He was not at all concerned about what was happening.\n",
      "Real label: 1\n",
      "Predicted label: 1\n",
      "\n",
      "Premise: Започвам живота с дарение от сто круши и хиляда ябълки.\n",
      "Hypothesis: Моят баща ми даде плода.\n",
      "Real label: 1\n",
      "Predicted label: 2\n",
      "\n",
      "Accuracy: 32.51%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "premise_predicted = new_df.iloc[test_indices]['premise']\n",
    "label_real = new_df.iloc[test_indices]['label']\n",
    "hypothesis_predicted = new_df.iloc[test_indices]['hypothesis']\n",
    "\n",
    "for premise,hypothesis, label_real, label_pred in zip(premise_predicted.head(30),hypothesis_predicted.head(30),label_real.head(30), y_pred[:30]):\n",
    "    print(f\"Premise: {premise}\\nHypothesis: {hypothesis}\\nReal label: {label_real}\\nPredicted label: {label_pred}\\n\")   \n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the results aren't good: we get a **32% accuracy**, which is approximately as good as randomly classifying the sentences.\n",
    "\n",
    "We can easily understand why a Word2Vec-based approach isn't well-suited for an entailment task. Two embeddings generated by this method will be very close in the embedding space if they share similar **syntax** or contain many of the same words. However, **semantic similarity** and **logical entailment** go beyond surface-level word overlap. Two sentences can have similar words but completely different meanings or intentions.\n",
    "\n",
    "Let’s take an example:\n",
    "\n",
    "- **Premise:** *The Journal put the point succinctly: \"Is any publicity good publicity?\"*\n",
    "- **Hypothesis:** *The Journal asked, \"Is this a good political move?\"*\n",
    "\n",
    "These sentences are unrelated in meaning, yet the classifier labeled them as contradicting.\n",
    "\n",
    "This misclassification happens because their sentence embeddings, derived from Word2Vec averaging, are close in vector space due to overlapping words like *\"The Journal,\"* *\"asked,\"* and *\"good.\"* However, the relationship between the sentences is **neutral**, not contradictory. Word2Vec lacks the ability to capture context, negation, or logical structure, which are crucial for tasks like natural language inference.\n",
    "\n",
    "This example shows the limitations of using shallow embedding methods for semantic understanding, and why more **context-aware models** like `BERT` or other transformer-based models are better suited for such tasks. That's what we are going to delve into next.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
